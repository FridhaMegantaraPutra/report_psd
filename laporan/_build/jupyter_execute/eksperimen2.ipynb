{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Ganti 'nama_folder' dengan nama folder yang ingin Anda masuki\n",
    "path = 'suara'\n",
    "\n",
    "# Gunakan metode `chdir` untuk berpindah ke folder tersebut\n",
    "os.chdir(path)\n",
    "\n",
    "# Sekarang Anda berada di dalam folder tersebut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7cnyeP6YJFLw"
   },
   "outputs": [],
   "source": [
    "folders=['YAF_sad','YAF_pleasant_surprised','YAF_neutral',\n",
    "         'YAF_happy','YAF_fear','YAF_disgust','YAF_angry',\n",
    "         'OAF_Sad','OAF_Pleasant_surprise','OAF_neutral',\n",
    "         'OAF_happy','OAF_Fear','OAF_disgust',\n",
    "         'OAF_angry',\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1IoLq3CrIvqT"
   },
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3UvuFfxiIxZ0"
   },
   "outputs": [],
   "source": [
    "def calculate_statistics(audio_path):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "\n",
    "    # UNTUK MENGHITUNG NILAI STATISTIKA\n",
    "    mean = np.mean(y)\n",
    "    std_dev = np.std(y)\n",
    "    max_value = np.max(y)\n",
    "    min_value = np.min(y)\n",
    "    median = np.median(y)\n",
    "    skewness = skew(y)  # Calculate skewness\n",
    "    kurt = kurtosis(y)  # Calculate kurtosis\n",
    "    q1 = np.percentile(y, 25)\n",
    "    q3 = np.percentile(y, 75)\n",
    "    mode_value, _ = mode(y)  # Calculate mode\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # UNTUK MENGHITUNG NILAI ZCR\n",
    "    zcr_mean = np.mean(librosa.feature.zero_crossing_rate(y=y))\n",
    "    zcr_median = np.median(librosa.feature.zero_crossing_rate(y=y))\n",
    "    zcr_std_dev = np.std(librosa.feature.zero_crossing_rate(y=y))\n",
    "    zcr_kurtosis = kurtosis(librosa.feature.zero_crossing_rate(y=y)[0])\n",
    "    zcr_skew = skew(librosa.feature.zero_crossing_rate(y=y)[0])\n",
    "\n",
    "    # UNTUK MENGHITUNG NILAI RMSE\n",
    "    rmse = np.sum(y**2) / len(y)\n",
    "    rmse_median = np.median(y**2)\n",
    "    rmse_std_dev = np.std(y**2)\n",
    "    rmse_kurtosis = kurtosis(y**2)\n",
    "    rmse_skew = skew(y**2)\n",
    "\n",
    "    return [zcr_mean, zcr_median, zcr_std_dev, zcr_kurtosis, zcr_skew, rmse, rmse_median, rmse_std_dev, rmse_kurtosis, rmse_skew]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0wJlTo7kNEEd"
   },
   "outputs": [],
   "source": [
    "features =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Kn6_bbxXOTcQ"
   },
   "outputs": [],
   "source": [
    "# Membuat DataFrame dari data\n",
    "columns =  ['Label', 'File'] + ['ZCR Mean', 'ZCR Median', 'ZCR Std Dev', 'ZCR Kurtosis', 'ZCR Skew', 'RMSE', 'RMSE Median', 'RMSE Std Dev', 'RMSE Kurtosis', 'RMSE Skew']\n",
    "df = pd.DataFrame(features, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-5U2IFl1OYtA"
   },
   "outputs": [],
   "source": [
    "df.to_csv('emosi2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "RkLvmkojOXDi",
    "outputId": "eb0f8559-22a2-40b8-edf8-ff66ddc259be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>File</th>\n",
       "      <th>ZCR Mean</th>\n",
       "      <th>ZCR Median</th>\n",
       "      <th>ZCR Std Dev</th>\n",
       "      <th>ZCR Kurtosis</th>\n",
       "      <th>ZCR Skew</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RMSE Median</th>\n",
       "      <th>RMSE Std Dev</th>\n",
       "      <th>RMSE Kurtosis</th>\n",
       "      <th>RMSE Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Label, File, ZCR Mean, ZCR Median, ZCR Std Dev, ZCR Kurtosis, ZCR Skew, RMSE, RMSE Median, RMSE Std Dev, RMSE Kurtosis, RMSE Skew]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan file CSV\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yz51emzFOgod"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 10)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Lakukan standarisasi pada kolom yang telah ditentukan\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m dn[kolom] \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkolom\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Simpan DataFrame yang telah distandarisasi ke dalam file CSV baru\u001b[39;00m\n\u001b[0;32m     11\u001b[0m dn\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memosi2normalisasi.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    877\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:824\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:861\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m    860\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 861\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    868\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 931\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    932\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    933\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    934\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    935\u001b[0m         )\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    938\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 10)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Baca file CSV\n",
    "dn = pd.read_csv(\"emosi2.csv\")\n",
    "# Tentukan kolom yang akan distandarisasi\n",
    "kolom = ['ZCR Mean', 'ZCR Median', 'ZCR Std Dev', 'ZCR Kurtosis', 'ZCR Skew', 'RMSE', 'RMSE Median', 'RMSE Std Dev', 'RMSE Kurtosis', 'RMSE Skew']\n",
    "# Inisialisasi StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Lakukan standarisasi pada kolom yang telah ditentukan\n",
    "dn[kolom] = scaler.fit_transform(dn[kolom])\n",
    "# Simpan DataFrame yang telah distandarisasi ke dalam file CSV baru\n",
    "dn.to_csv(\"emosi2normalisasi.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "HkIvSnAPOjYP",
    "outputId": "f324281c-0883-42ae-fc96-879870ccba67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>File</th>\n",
       "      <th>ZCR Mean</th>\n",
       "      <th>ZCR Median</th>\n",
       "      <th>ZCR Std Dev</th>\n",
       "      <th>ZCR Kurtosis</th>\n",
       "      <th>ZCR Skew</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RMSE Median</th>\n",
       "      <th>RMSE Std Dev</th>\n",
       "      <th>RMSE Kurtosis</th>\n",
       "      <th>RMSE Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YAF_sad</td>\n",
       "      <td>YAF_back_sad.wav</td>\n",
       "      <td>-0.321317</td>\n",
       "      <td>-1.052521</td>\n",
       "      <td>0.940845</td>\n",
       "      <td>0.204442</td>\n",
       "      <td>0.495211</td>\n",
       "      <td>-0.034644</td>\n",
       "      <td>0.841023</td>\n",
       "      <td>-0.124395</td>\n",
       "      <td>-0.391352</td>\n",
       "      <td>-0.278648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YAF_sad</td>\n",
       "      <td>YAF_bar_sad.wav</td>\n",
       "      <td>-0.643634</td>\n",
       "      <td>-0.962423</td>\n",
       "      <td>0.324040</td>\n",
       "      <td>1.185171</td>\n",
       "      <td>1.219225</td>\n",
       "      <td>-0.141582</td>\n",
       "      <td>0.428966</td>\n",
       "      <td>-0.217270</td>\n",
       "      <td>-0.455914</td>\n",
       "      <td>-0.367812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YAF_sad</td>\n",
       "      <td>YAF_base_sad.wav</td>\n",
       "      <td>0.936230</td>\n",
       "      <td>-0.767212</td>\n",
       "      <td>1.676354</td>\n",
       "      <td>-1.517779</td>\n",
       "      <td>-1.507027</td>\n",
       "      <td>-0.138627</td>\n",
       "      <td>0.086704</td>\n",
       "      <td>-0.232522</td>\n",
       "      <td>-0.535851</td>\n",
       "      <td>-0.557901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YAF_sad</td>\n",
       "      <td>YAF_bath_sad.wav</td>\n",
       "      <td>-0.007778</td>\n",
       "      <td>-0.872326</td>\n",
       "      <td>0.883874</td>\n",
       "      <td>-0.089302</td>\n",
       "      <td>0.059975</td>\n",
       "      <td>-0.128325</td>\n",
       "      <td>0.484321</td>\n",
       "      <td>-0.214498</td>\n",
       "      <td>-0.373958</td>\n",
       "      <td>-0.308835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YAF_sad</td>\n",
       "      <td>YAF_bean_sad.wav</td>\n",
       "      <td>-0.750198</td>\n",
       "      <td>-0.992456</td>\n",
       "      <td>0.282586</td>\n",
       "      <td>1.448416</td>\n",
       "      <td>1.447698</td>\n",
       "      <td>-0.268086</td>\n",
       "      <td>0.324541</td>\n",
       "      <td>-0.385308</td>\n",
       "      <td>-0.719553</td>\n",
       "      <td>-0.915580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>OAF_angry</td>\n",
       "      <td>OAF_witch_angry.wav</td>\n",
       "      <td>-0.941158</td>\n",
       "      <td>0.103730</td>\n",
       "      <td>-2.051468</td>\n",
       "      <td>-0.023647</td>\n",
       "      <td>-0.479064</td>\n",
       "      <td>-0.444378</td>\n",
       "      <td>-0.610274</td>\n",
       "      <td>-0.400092</td>\n",
       "      <td>0.317051</td>\n",
       "      <td>0.553880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>OAF_angry</td>\n",
       "      <td>OAF_yearn_angry.wav</td>\n",
       "      <td>-1.149659</td>\n",
       "      <td>-0.496920</td>\n",
       "      <td>-1.895834</td>\n",
       "      <td>2.196348</td>\n",
       "      <td>1.573026</td>\n",
       "      <td>0.382521</td>\n",
       "      <td>0.413899</td>\n",
       "      <td>0.189645</td>\n",
       "      <td>-0.579294</td>\n",
       "      <td>-0.658240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>OAF_angry</td>\n",
       "      <td>OAF_yes_angry.wav</td>\n",
       "      <td>-0.573586</td>\n",
       "      <td>-0.226627</td>\n",
       "      <td>-1.322985</td>\n",
       "      <td>0.274090</td>\n",
       "      <td>0.087558</td>\n",
       "      <td>-0.095713</td>\n",
       "      <td>-0.205668</td>\n",
       "      <td>-0.083510</td>\n",
       "      <td>-0.067049</td>\n",
       "      <td>0.155834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>OAF_angry</td>\n",
       "      <td>OAF_young_angry.wav</td>\n",
       "      <td>-1.130833</td>\n",
       "      <td>-0.256660</td>\n",
       "      <td>-1.932072</td>\n",
       "      <td>1.273526</td>\n",
       "      <td>0.919734</td>\n",
       "      <td>-0.187424</td>\n",
       "      <td>-0.254658</td>\n",
       "      <td>-0.133875</td>\n",
       "      <td>-0.320661</td>\n",
       "      <td>-0.086440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>OAF_angry</td>\n",
       "      <td>OAF_youth_angry.wav</td>\n",
       "      <td>-1.324499</td>\n",
       "      <td>-0.587017</td>\n",
       "      <td>-1.750587</td>\n",
       "      <td>2.491151</td>\n",
       "      <td>1.906111</td>\n",
       "      <td>0.031379</td>\n",
       "      <td>-0.225293</td>\n",
       "      <td>-0.035495</td>\n",
       "      <td>-0.455012</td>\n",
       "      <td>-0.456902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Label                 File  ZCR Mean  ZCR Median  ZCR Std Dev  \\\n",
       "0       YAF_sad     YAF_back_sad.wav -0.321317   -1.052521     0.940845   \n",
       "1       YAF_sad      YAF_bar_sad.wav -0.643634   -0.962423     0.324040   \n",
       "2       YAF_sad     YAF_base_sad.wav  0.936230   -0.767212     1.676354   \n",
       "3       YAF_sad     YAF_bath_sad.wav -0.007778   -0.872326     0.883874   \n",
       "4       YAF_sad     YAF_bean_sad.wav -0.750198   -0.992456     0.282586   \n",
       "...         ...                  ...       ...         ...          ...   \n",
       "2795  OAF_angry  OAF_witch_angry.wav -0.941158    0.103730    -2.051468   \n",
       "2796  OAF_angry  OAF_yearn_angry.wav -1.149659   -0.496920    -1.895834   \n",
       "2797  OAF_angry    OAF_yes_angry.wav -0.573586   -0.226627    -1.322985   \n",
       "2798  OAF_angry  OAF_young_angry.wav -1.130833   -0.256660    -1.932072   \n",
       "2799  OAF_angry  OAF_youth_angry.wav -1.324499   -0.587017    -1.750587   \n",
       "\n",
       "      ZCR Kurtosis  ZCR Skew      RMSE  RMSE Median  RMSE Std Dev  \\\n",
       "0         0.204442  0.495211 -0.034644     0.841023     -0.124395   \n",
       "1         1.185171  1.219225 -0.141582     0.428966     -0.217270   \n",
       "2        -1.517779 -1.507027 -0.138627     0.086704     -0.232522   \n",
       "3        -0.089302  0.059975 -0.128325     0.484321     -0.214498   \n",
       "4         1.448416  1.447698 -0.268086     0.324541     -0.385308   \n",
       "...            ...       ...       ...          ...           ...   \n",
       "2795     -0.023647 -0.479064 -0.444378    -0.610274     -0.400092   \n",
       "2796      2.196348  1.573026  0.382521     0.413899      0.189645   \n",
       "2797      0.274090  0.087558 -0.095713    -0.205668     -0.083510   \n",
       "2798      1.273526  0.919734 -0.187424    -0.254658     -0.133875   \n",
       "2799      2.491151  1.906111  0.031379    -0.225293     -0.035495   \n",
       "\n",
       "      RMSE Kurtosis  RMSE Skew  \n",
       "0         -0.391352  -0.278648  \n",
       "1         -0.455914  -0.367812  \n",
       "2         -0.535851  -0.557901  \n",
       "3         -0.373958  -0.308835  \n",
       "4         -0.719553  -0.915580  \n",
       "...             ...        ...  \n",
       "2795       0.317051   0.553880  \n",
       "2796      -0.579294  -0.658240  \n",
       "2797      -0.067049   0.155834  \n",
       "2798      -0.320661  -0.086440  \n",
       "2799      -0.455012  -0.456902  \n",
       "\n",
       "[2800 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm=pd.read_csv('emosi2normalisasi.csv')\n",
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hy1DVx3MOnQc",
    "outputId": "a81634d5-e544-4685-d8ef-eb8d30bdbd96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--MEAN--\n",
      "ZCR Mean         0.0\n",
      "ZCR Median       0.0\n",
      "ZCR Std Dev     -0.0\n",
      "ZCR Kurtosis     0.0\n",
      "ZCR Skew        -0.0\n",
      "RMSE             0.0\n",
      "RMSE Median     -0.0\n",
      "RMSE Std Dev     0.0\n",
      "RMSE Kurtosis   -0.0\n",
      "RMSE Skew       -0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Daftar kolom yang ingin dilewati\n",
    "kolomlabel= ['Label','File',]\n",
    "# Menghitung rata-rata untuk kolom numerik tertentu (mengabaikan kolom yang tidak diinginkan)\n",
    "rata2= norm.drop(columns=kolomlabel).mean()\n",
    "#membulatkan hasil komputasi dengan round dengan ketentuan 2 setelah koma, biar ga panjang bestiiiiiii\n",
    "dibulatkan=rata2.round(2)\n",
    "# Menampilkan rata-rata\n",
    "print('--MEAN--')\n",
    "print(dibulatkan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMnYFTreOptL",
    "outputId": "d585b2fd-b7fd-4780-ce8a-04b9188be32d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--STANDARD DEVIASI--\n",
      "ZCR Mean         1.0\n",
      "ZCR Median       1.0\n",
      "ZCR Std Dev      1.0\n",
      "ZCR Kurtosis     1.0\n",
      "ZCR Skew         1.0\n",
      "RMSE             1.0\n",
      "RMSE Median      1.0\n",
      "RMSE Std Dev     1.0\n",
      "RMSE Kurtosis    1.0\n",
      "RMSE Skew        1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Daftar kolom yang ingin dilewati\n",
    "kolomlabel= ['Label','File']\n",
    "# Menghitung rata-rata untuk kolom numerik tertentu (mengabaikan kolom yang tidak diinginkan)\n",
    "standv= norm.drop(columns=kolomlabel).std()\n",
    "#membulatkan hasil komputasi dengan round dengan ketentuan 2 setelah koma, biar ga panjang bestiiiiiii\n",
    "bulatkan=standv.round(2)\n",
    "# Menampilkan rata-rata\n",
    "print('--STANDARD DEVIASI--')\n",
    "print(bulatkan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "WbKO-lDiOsDs"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "rGEmNDC2Outs"
   },
   "outputs": [],
   "source": [
    "# Baca data dari file CSV\n",
    "dataknn= pd.read_csv('emosi2.csv')\n",
    "# Pisahkan fitur (X) dan label (y)\n",
    "X = dataknn.drop(['Label','File'], axis=1)  # Ganti 'target_column' dengan nama kolom target\n",
    "y = dataknn['Label']\n",
    "# split data into train and test sets\n",
    "X_train,X_test,y_train, y_test= train_test_split(X, y, random_state=1, test_size=0.2)\n",
    "# define scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on the training dataset\n",
    "scaler.fit(X_train)\n",
    "# save the scaler\n",
    "dump(scaler, open('scaler.pkl', 'wb'))\n",
    "# transform the training dataset\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "SfUusAp6OxYM"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('scaler.pkl', 'rb') as standarisasi:\n",
    "    loadscal= pickle.load(standarisasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "9nbNvoF0O1uX"
   },
   "outputs": [],
   "source": [
    "X_test_scaled=loadscal.transform(X_test) #normalisasi X testing dari hasil normalisasi X train yang disimpan dalam model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Zw4TNBaWO1y9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "ktyDEVKVO8mF"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors= 1, metric = \"euclidean\")\n",
    "dump(knn, open('modelknn_k1.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "xqOx2kwxRSJb"
   },
   "outputs": [],
   "source": [
    "#array=np.array([0.1722103851,0.0419921875,0.2303348292,1.158274856,1.556415655,0.001505466753,0.00024307908,0.0033376536,24.95338147,4.40281652])\n",
    "#arnorm=loadscal.transform(array)\n",
    "#arnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "ypqYFTmFRDlQ",
    "outputId": "ec5da1e3-7118-4e5b-870c-346b973d64fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=13)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=13)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric='euclidean', n_neighbors=13)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('modelknn.sav', 'rb') as knn:\n",
    "    loadknn= pickle.load(knn)\n",
    "loadknn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ws1abLQSSx9",
    "outputId": "17cf42f6-2c50-409f-dd53-cbd593a46723"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OAF_happy', 'YAF_disgust', 'YAF_neutral', 'YAF_disgust',\n",
       "       'OAF_Fear', 'OAF_neutral', 'YAF_pleasant_surprised', 'OAF_angry',\n",
       "       'OAF_disgust', 'OAF_Sad', 'YAF_sad', 'YAF_sad', 'OAF_angry',\n",
       "       'OAF_angry', 'OAF_disgust', 'OAF_angry', 'OAF_Sad', 'YAF_neutral',\n",
       "       'OAF_angry', 'YAF_neutral', 'YAF_pleasant_surprised',\n",
       "       'OAF_neutral', 'OAF_Pleasant_surprise', 'YAF_pleasant_surprised',\n",
       "       'OAF_neutral', 'YAF_sad', 'YAF_pleasant_surprised', 'YAF_fear',\n",
       "       'OAF_happy', 'OAF_Fear', 'OAF_neutral', 'OAF_disgust',\n",
       "       'YAF_neutral', 'YAF_pleasant_surprised', 'YAF_pleasant_surprised',\n",
       "       'YAF_angry', 'OAF_Fear', 'OAF_Sad', 'YAF_happy', 'OAF_happy',\n",
       "       'YAF_disgust', 'OAF_Sad', 'YAF_neutral', 'YAF_happy',\n",
       "       'OAF_disgust', 'OAF_disgust', 'YAF_happy', 'YAF_disgust',\n",
       "       'OAF_neutral', 'OAF_neutral', 'OAF_happy', 'OAF_disgust',\n",
       "       'OAF_Sad', 'YAF_neutral', 'YAF_pleasant_surprised', 'OAF_disgust',\n",
       "       'OAF_angry', 'OAF_Pleasant_surprise', 'YAF_disgust', 'OAF_disgust',\n",
       "       'OAF_disgust', 'OAF_Fear', 'OAF_Sad', 'OAF_angry',\n",
       "       'YAF_pleasant_surprised', 'OAF_happy', 'OAF_angry', 'YAF_neutral',\n",
       "       'YAF_fear', 'YAF_fear', 'OAF_Sad', 'OAF_angry',\n",
       "       'OAF_Pleasant_surprise', 'OAF_happy', 'OAF_angry',\n",
       "       'YAF_pleasant_surprised', 'OAF_Fear', 'OAF_Sad', 'YAF_neutral',\n",
       "       'YAF_happy', 'YAF_neutral', 'YAF_neutral', 'YAF_angry',\n",
       "       'OAF_disgust', 'YAF_pleasant_surprised', 'YAF_fear', 'YAF_sad',\n",
       "       'YAF_disgust', 'YAF_angry', 'YAF_pleasant_surprised', 'YAF_fear',\n",
       "       'YAF_sad', 'YAF_angry', 'YAF_pleasant_surprised', 'OAF_happy',\n",
       "       'OAF_happy', 'YAF_neutral', 'YAF_neutral', 'YAF_fear', 'OAF_Fear',\n",
       "       'OAF_neutral', 'OAF_Pleasant_surprise', 'OAF_Fear', 'YAF_disgust',\n",
       "       'OAF_Pleasant_surprise', 'OAF_Sad', 'OAF_neutral', 'YAF_neutral',\n",
       "       'OAF_neutral', 'OAF_angry', 'OAF_disgust', 'YAF_sad', 'OAF_Sad',\n",
       "       'YAF_happy', 'OAF_Sad', 'YAF_fear', 'YAF_disgust', 'OAF_Fear',\n",
       "       'YAF_angry', 'OAF_Pleasant_surprise', 'OAF_disgust', 'YAF_sad',\n",
       "       'OAF_Fear', 'OAF_angry', 'YAF_angry', 'OAF_disgust', 'YAF_happy',\n",
       "       'OAF_Sad', 'YAF_disgust', 'YAF_fear', 'YAF_angry', 'YAF_disgust',\n",
       "       'OAF_neutral', 'YAF_angry', 'OAF_happy', 'YAF_happy', 'YAF_sad',\n",
       "       'YAF_disgust', 'OAF_Fear', 'OAF_neutral', 'YAF_sad', 'YAF_fear',\n",
       "       'YAF_neutral', 'YAF_disgust', 'OAF_Sad', 'YAF_happy', 'YAF_angry',\n",
       "       'YAF_pleasant_surprised', 'YAF_disgust', 'YAF_angry', 'YAF_angry',\n",
       "       'OAF_happy', 'OAF_angry', 'YAF_disgust', 'YAF_happy', 'YAF_happy',\n",
       "       'OAF_neutral', 'OAF_Pleasant_surprise', 'YAF_angry', 'OAF_neutral',\n",
       "       'OAF_neutral', 'OAF_neutral', 'YAF_sad', 'YAF_angry', 'OAF_Fear',\n",
       "       'OAF_happy', 'OAF_neutral', 'YAF_sad', 'YAF_pleasant_surprised',\n",
       "       'YAF_pleasant_surprised', 'OAF_neutral', 'YAF_fear', 'YAF_disgust',\n",
       "       'YAF_sad', 'YAF_happy', 'YAF_sad', 'OAF_Sad', 'OAF_happy',\n",
       "       'YAF_neutral', 'YAF_pleasant_surprised', 'YAF_pleasant_surprised',\n",
       "       'YAF_disgust', 'YAF_fear', 'YAF_angry', 'YAF_angry', 'YAF_happy',\n",
       "       'YAF_pleasant_surprised', 'OAF_happy', 'YAF_happy',\n",
       "       'YAF_pleasant_surprised', 'OAF_Sad', 'OAF_Sad', 'YAF_fear',\n",
       "       'YAF_neutral', 'OAF_happy', 'OAF_neutral', 'YAF_happy',\n",
       "       'YAF_disgust', 'YAF_fear', 'YAF_angry', 'OAF_disgust', 'OAF_Sad',\n",
       "       'OAF_neutral', 'YAF_pleasant_surprised', 'OAF_disgust',\n",
       "       'OAF_disgust', 'OAF_angry', 'OAF_Fear', 'OAF_disgust',\n",
       "       'OAF_disgust', 'OAF_Sad', 'OAF_neutral', 'OAF_Fear', 'YAF_disgust',\n",
       "       'YAF_disgust', 'YAF_pleasant_surprised', 'OAF_Pleasant_surprise',\n",
       "       'OAF_Pleasant_surprise', 'OAF_angry', 'OAF_Fear', 'OAF_Fear',\n",
       "       'OAF_Fear', 'YAF_pleasant_surprised', 'YAF_neutral', 'OAF_neutral',\n",
       "       'YAF_neutral', 'YAF_happy', 'YAF_fear', 'OAF_disgust', 'YAF_sad',\n",
       "       'OAF_happy', 'YAF_pleasant_surprised', 'OAF_Fear',\n",
       "       'YAF_pleasant_surprised', 'OAF_Fear', 'YAF_fear', 'YAF_fear',\n",
       "       'OAF_Sad', 'OAF_neutral', 'OAF_Sad', 'YAF_disgust', 'YAF_happy',\n",
       "       'YAF_sad', 'YAF_disgust', 'OAF_happy', 'OAF_Fear',\n",
       "       'YAF_pleasant_surprised', 'OAF_disgust', 'YAF_sad', 'YAF_sad',\n",
       "       'OAF_happy', 'YAF_sad', 'OAF_Sad', 'OAF_neutral', 'OAF_neutral',\n",
       "       'OAF_disgust', 'OAF_Sad', 'YAF_fear', 'OAF_Fear', 'OAF_disgust',\n",
       "       'YAF_happy', 'OAF_neutral', 'OAF_happy', 'YAF_sad',\n",
       "       'OAF_Pleasant_surprise', 'YAF_angry', 'OAF_happy', 'OAF_Fear',\n",
       "       'YAF_angry', 'OAF_disgust', 'YAF_angry', 'YAF_disgust',\n",
       "       'OAF_happy', 'YAF_fear', 'OAF_Pleasant_surprise', 'YAF_angry',\n",
       "       'OAF_angry', 'OAF_Fear', 'YAF_neutral', 'OAF_Sad', 'YAF_happy',\n",
       "       'OAF_Pleasant_surprise', 'YAF_disgust', 'YAF_sad',\n",
       "       'OAF_Pleasant_surprise', 'OAF_disgust', 'OAF_Sad', 'YAF_angry',\n",
       "       'YAF_happy', 'OAF_happy', 'OAF_neutral', 'YAF_pleasant_surprised',\n",
       "       'OAF_neutral', 'OAF_disgust', 'OAF_neutral',\n",
       "       'OAF_Pleasant_surprise', 'OAF_disgust', 'OAF_Sad', 'YAF_happy',\n",
       "       'OAF_neutral', 'OAF_disgust', 'YAF_happy', 'YAF_angry',\n",
       "       'OAF_neutral', 'YAF_pleasant_surprised', 'YAF_neutral',\n",
       "       'OAF_angry', 'YAF_disgust', 'YAF_pleasant_surprised',\n",
       "       'OAF_neutral', 'OAF_angry', 'YAF_sad', 'OAF_disgust', 'OAF_Sad',\n",
       "       'OAF_Fear', 'OAF_happy', 'OAF_Fear', 'YAF_pleasant_surprised',\n",
       "       'YAF_angry', 'YAF_sad', 'YAF_pleasant_surprised',\n",
       "       'OAF_Pleasant_surprise', 'YAF_sad', 'YAF_disgust', 'OAF_neutral',\n",
       "       'OAF_neutral', 'OAF_Sad', 'YAF_fear', 'OAF_happy', 'OAF_happy',\n",
       "       'OAF_Pleasant_surprise', 'YAF_neutral', 'OAF_disgust',\n",
       "       'YAF_disgust', 'OAF_Sad', 'YAF_angry', 'YAF_disgust', 'OAF_Sad',\n",
       "       'OAF_Sad', 'OAF_disgust', 'OAF_neutral', 'YAF_fear', 'YAF_fear',\n",
       "       'YAF_disgust', 'YAF_pleasant_surprised', 'OAF_Fear', 'YAF_disgust',\n",
       "       'OAF_Fear', 'OAF_disgust', 'YAF_disgust', 'OAF_Pleasant_surprise',\n",
       "       'OAF_happy', 'YAF_fear', 'OAF_Fear', 'YAF_angry', 'OAF_happy',\n",
       "       'OAF_Sad', 'OAF_Fear', 'OAF_Pleasant_surprise', 'YAF_disgust',\n",
       "       'OAF_neutral', 'YAF_disgust', 'YAF_happy', 'YAF_disgust',\n",
       "       'OAF_angry', 'YAF_neutral', 'OAF_happy', 'YAF_happy',\n",
       "       'YAF_neutral', 'YAF_sad', 'YAF_sad', 'OAF_disgust', 'YAF_neutral',\n",
       "       'OAF_happy', 'YAF_disgust', 'YAF_happy', 'OAF_happy',\n",
       "       'YAF_disgust', 'OAF_happy', 'OAF_happy', 'YAF_angry', 'YAF_happy',\n",
       "       'OAF_disgust', 'OAF_happy', 'OAF_angry', 'YAF_sad', 'YAF_sad',\n",
       "       'YAF_fear', 'OAF_angry', 'OAF_happy', 'YAF_fear', 'YAF_neutral',\n",
       "       'OAF_neutral', 'YAF_disgust', 'OAF_Fear', 'OAF_disgust',\n",
       "       'OAF_Fear', 'YAF_happy', 'YAF_neutral', 'YAF_sad', 'OAF_angry',\n",
       "       'YAF_angry', 'OAF_disgust', 'YAF_angry', 'OAF_happy',\n",
       "       'OAF_Pleasant_surprise', 'OAF_angry', 'YAF_happy', 'OAF_angry',\n",
       "       'OAF_happy', 'YAF_disgust', 'OAF_Sad', 'OAF_disgust',\n",
       "       'OAF_Pleasant_surprise', 'YAF_angry', 'OAF_angry',\n",
       "       'OAF_Pleasant_surprise', 'YAF_neutral', 'YAF_disgust', 'YAF_happy',\n",
       "       'OAF_Sad', 'OAF_Fear', 'OAF_Sad', 'OAF_angry',\n",
       "       'OAF_Pleasant_surprise', 'YAF_neutral', 'OAF_Sad', 'YAF_disgust',\n",
       "       'YAF_neutral', 'YAF_disgust', 'YAF_neutral',\n",
       "       'YAF_pleasant_surprised', 'OAF_disgust', 'YAF_happy', 'OAF_Fear',\n",
       "       'OAF_Fear', 'OAF_Pleasant_surprise', 'YAF_fear', 'OAF_Sad',\n",
       "       'YAF_fear', 'OAF_Pleasant_surprise', 'OAF_neutral', 'OAF_disgust',\n",
       "       'YAF_happy', 'YAF_disgust', 'YAF_sad', 'OAF_neutral',\n",
       "       'OAF_Pleasant_surprise', 'YAF_disgust', 'YAF_pleasant_surprised',\n",
       "       'YAF_angry', 'YAF_happy', 'YAF_happy', 'YAF_neutral', 'OAF_Sad',\n",
       "       'YAF_angry', 'OAF_disgust', 'YAF_neutral', 'OAF_Pleasant_surprise',\n",
       "       'YAF_pleasant_surprised', 'OAF_Sad', 'YAF_neutral',\n",
       "       'YAF_pleasant_surprised', 'OAF_happy', 'YAF_sad', 'YAF_neutral',\n",
       "       'YAF_disgust', 'OAF_disgust', 'OAF_happy', 'YAF_sad', 'OAF_angry',\n",
       "       'YAF_fear', 'YAF_happy', 'YAF_disgust', 'YAF_happy', 'OAF_happy',\n",
       "       'YAF_fear', 'OAF_Sad', 'YAF_neutral', 'OAF_Sad', 'YAF_happy',\n",
       "       'OAF_Sad', 'YAF_disgust', 'YAF_happy', 'OAF_neutral',\n",
       "       'YAF_neutral', 'YAF_neutral', 'YAF_happy', 'YAF_happy',\n",
       "       'OAF_happy', 'YAF_disgust', 'YAF_pleasant_surprised', 'OAF_Fear',\n",
       "       'OAF_Sad', 'OAF_Sad', 'OAF_Sad', 'OAF_Fear', 'YAF_fear',\n",
       "       'YAF_pleasant_surprised', 'YAF_disgust', 'YAF_happy', 'YAF_sad',\n",
       "       'YAF_neutral', 'OAF_angry', 'YAF_pleasant_surprised',\n",
       "       'OAF_disgust', 'YAF_happy', 'YAF_fear', 'YAF_happy', 'OAF_Fear',\n",
       "       'OAF_happy', 'YAF_sad', 'OAF_Pleasant_surprise', 'OAF_happy',\n",
       "       'OAF_happy', 'YAF_neutral', 'YAF_happy', 'OAF_neutral',\n",
       "       'YAF_angry', 'YAF_disgust', 'OAF_happy', 'YAF_angry', 'YAF_fear',\n",
       "       'OAF_disgust', 'OAF_disgust', 'YAF_happy',\n",
       "       'YAF_pleasant_surprised', 'OAF_happy', 'YAF_angry', 'YAF_happy',\n",
       "       'YAF_neutral', 'YAF_disgust', 'OAF_Sad', 'OAF_Pleasant_surprise',\n",
       "       'OAF_Pleasant_surprise', 'OAF_Pleasant_surprise', 'OAF_angry',\n",
       "       'OAF_angry', 'OAF_happy', 'OAF_angry', 'OAF_disgust',\n",
       "       'OAF_disgust', 'OAF_neutral', 'YAF_happy', 'OAF_neutral',\n",
       "       'YAF_disgust', 'YAF_happy', 'YAF_fear', 'OAF_neutral', 'YAF_angry',\n",
       "       'YAF_pleasant_surprised', 'OAF_Fear', 'OAF_neutral', 'OAF_happy',\n",
       "       'OAF_disgust', 'YAF_pleasant_surprised', 'YAF_pleasant_surprised',\n",
       "       'OAF_angry', 'OAF_Sad', 'YAF_disgust'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = loadknn.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YEvb72Q0SWQF",
    "outputId": "6088b63f-1e7f-40f8-e9c8-3c0645c250cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi: 0.7053571428571429\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"Akurasi:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import streamlit as st\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pickle import dump\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import skew, kurtosis, mode\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNeighborsClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m knn \u001b[38;5;241m=\u001b[39m \u001b[43mKNeighborsClassifier\u001b[49m(n_neighbors\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train)\n\u001b[0;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n\u001b[0;32m      4\u001b[0m acc[n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m=\u001b[39m accuracy_score(y_test,y_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KNeighborsClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors= 1, metric = \"euclidean\").fit(X_train_scaled, y_train)\n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "    acc[n-1]= accuracy_score(y_test,y_pred)\n",
    "\n",
    "print('akurasi terbaik adalah ', acc.max(), 'dengan nilai k =', acc.argmax()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hitung_statistik(audio_file):\n",
    "    zcr_data = pd.DataFrame(columns=[\n",
    "                            'ZCR Mean', 'ZCR Median', 'ZCR Std Deviasi', 'ZCR Skewness', 'ZCR Kurtosis'])\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    mean = np.mean(y)\n",
    "    std_dev = np.std(y)\n",
    "    max_value = np.max(y)\n",
    "    min_value = np.min(y)\n",
    "    median = np.median(y)\n",
    "    skewness = skew(y)  # Calculate skewness\n",
    "    kurt = kurtosis(y)  # Calculate kurtosis\n",
    "    q1 = np.percentile(y, 25)\n",
    "    q3 = np.percentile(y, 75)\n",
    "    mode_value, _ = mode(y)  # Calculate mode\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # Hitung ZCR\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    # Hitung rata-rata ZCR\n",
    "    mean_zcr = zcr.mean()\n",
    "    # Hitung nilai median ZCR\n",
    "    median_zcr = np.median(zcr)\n",
    "    # Hitung nilai std deviasa ZCR\n",
    "    std_dev_zcr = np.std(zcr)\n",
    "    # Hitung skewness ZCR\n",
    "    skewness_zcr = stats.skew(zcr, axis=None)\n",
    "    # Hitung kurtosis ZCR\n",
    "    kurtosis_zcr = stats.kurtosis(zcr, axis=None)\n",
    "\n",
    "    # Hitung RMS\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    # Hitung rata-rata RMS\n",
    "    mean_rms = rms.mean()\n",
    "    # Hitung nilai median RMS\n",
    "    median_rms = np.median(rms)\n",
    "    # Hitung nilai std deviasa RMS\n",
    "    std_dev_rms = np.std(rms)\n",
    "    # Hitung skewness RMS\n",
    "    skewness_rms = stats.skew(rms, axis=None)\n",
    "    # Hitung kurtosis RMS\n",
    "    kurtosis_rms = stats.kurtosis(rms, axis=None)\n",
    "\n",
    "    # Tambahkan data ke DataFrame\n",
    "    # return[mean, std_dev, max_value, min_value, median, skewness, kurt, q1, q3, mode_value, iqr, mean_zcr, median_zcr, std_dev_zcr, skewness_zcr, kurtosis_zcr, mean_rms, median_rms,std_dev_rms, skewness_rms, kurtosis_rms]\n",
    "    zcr_data = zcr_data._append({'ZCR Mean': mean_zcr, 'ZCR Median': median_zcr,\n",
    "                                'ZCR Std Deviasi': std_dev_zcr, 'ZCR Skewness': skewness_zcr, 'ZCR Kurtosis': kurtosis_zcr, }, ignore_index=True)\n",
    "    return zcr_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hitung_statistik.pkl', 'wb') as file_pickle:\n",
    "    pickle.dump(hitung_statistik, file_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "sklearn_pca = PCA(n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"sklearn_pca.pkl\"\n",
    "\n",
    "# Simpan objek PCA ke dalam berkas\n",
    "with open(file_name, 'wb') as file:\n",
    "    pickle.dump(sklearn_pca, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Menggunakan fungsi untuk PCA\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m pca_model \u001b[38;5;241m=\u001b[39m apply_pca(\u001b[43mX_train_scaled\u001b[49m, data_ternormalisasi, data_MinimMaxim)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# Menggunakan fungsi untuk PCA\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     MM_pca \u001b[38;5;241m=\u001b[39m sklearn_pca\u001b[38;5;241m.\u001b[39mtransform(data_MinimMaxim)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sklearn_pca\n\u001b[1;32m----> 8\u001b[0m pca_model \u001b[38;5;241m=\u001b[39m apply_pca(\u001b[43mX_train_scaled\u001b[49m, data_ternormalisasi, data_MinimMaxim)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "def apply_pca(X_train_scaled, data_ternormalisasi, data_MinimMaxim):\n",
    "    sklearn_pca = PCA(n_components=1)\n",
    "    X_train_pca = sklearn_pca.fit_transform(X_train_scaled)\n",
    "    X_pca = sklearn_pca.transform(data_ternormalisasi)\n",
    "    MM_pca = sklearn_pca.transform(data_MinimMaxim)\n",
    "    return sklearn_pca\n",
    "\n",
    "pca_model = apply_pca(X_train_scaled, data_ternormalisasi, data_MinimMaxim)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitung_statistik(audio_file):\n",
    "    zcr_data = pd.DataFrame(columns=[\n",
    "                            'ZCR Mean', 'ZCR Median', 'ZCR Std Deviasi', 'ZCR Skewness', 'ZCR Kurtosis'])\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    mean = np.mean(y)\n",
    "    std_dev = np.std(y)\n",
    "    max_value = np.max(y)\n",
    "    min_value = np.min(y)\n",
    "    median = np.median(y)\n",
    "    skewness = skew(y)  # Calculate skewness\n",
    "    kurt = kurtosis(y)  # Calculate kurtosis\n",
    "    q1 = np.percentile(y, 25)\n",
    "    q3 = np.percentile(y, 75)\n",
    "    mode_value, _ = mode(y)  # Calculate mode\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # Hitung ZCR\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    # Hitung rata-rata ZCR\n",
    "    mean_zcr = zcr.mean()\n",
    "    # Hitung nilai median ZCR\n",
    "    median_zcr = np.median(zcr)\n",
    "    # Hitung nilai std deviasa ZCR\n",
    "    std_dev_zcr = np.std(zcr)\n",
    "    # Hitung skewness ZCR\n",
    "    skewness_zcr = stats.skew(zcr, axis=None)\n",
    "    # Hitung kurtosis ZCR\n",
    "    kurtosis_zcr = stats.kurtosis(zcr, axis=None)\n",
    "\n",
    "    # Hitung RMS\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    # Hitung rata-rata RMS\n",
    "    mean_rms = rms.mean()\n",
    "    # Hitung nilai median RMS\n",
    "    median_rms = np.median(rms)\n",
    "    # Hitung nilai std deviasa RMS\n",
    "    std_dev_rms = np.std(rms)\n",
    "    # Hitung skewness RMS\n",
    "    skewness_rms = stats.skew(rms, axis=None)\n",
    "    # Hitung kurtosis RMS\n",
    "    kurtosis_rms = stats.kurtosis(rms, axis=None)\n",
    "\n",
    "    # Tambahkan data ke DataFrame\n",
    "    # return[mean, std_dev, max_value, min_value, median, skewness, kurt, q1, q3, mode_value, iqr, mean_zcr, median_zcr, std_dev_zcr, skewness_zcr, kurtosis_zcr, mean_rms, median_rms,std_dev_rms, skewness_rms, kurtosis_rms]\n",
    "    zcr_data = zcr_data._append({'ZCR Mean': mean_zcr, 'ZCR Median': median_zcr,\n",
    "                                'ZCR Std Deviasi': std_dev_zcr, 'ZCR Skewness': skewness_zcr, 'ZCR Kurtosis': kurtosis_zcr, }, ignore_index=True)\n",
    "    return zcr_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MinMaxScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m MinMax \u001b[38;5;241m=\u001b[39m \u001b[43mMinMaxScaler\u001b[49m(feature_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinmax.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m scaler_file:\n\u001b[0;32m      3\u001b[0m    pickle\u001b[38;5;241m.\u001b[39mdump(MinimMaximscaler, scaler_file)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MinMaxScaler' is not defined"
     ]
    }
   ],
   "source": [
    " MinMax = MinMaxScaler(feature_range=(0, 1))\n",
    "with open(\"Minmax.pkl\", \"wb\") as scaler_file:\n",
    "    pickle.dump(MinimMaximscaler, scaler_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import streamlit as st\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pickle import dump\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import skew, kurtosis, mode\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import streamlit as st\n",
    "\n",
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "MinMaxscaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Simpan objek MinMaxScaler ke dalam file pkl\n",
    "with open(\"MinMaxScaler.pkl\", \"wb\") as scaler_file:\n",
    "    joblib.dump(MinMaxscaler, scaler_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}